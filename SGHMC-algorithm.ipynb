{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n = 100\n",
    "x = np.array([np.random.normal(0, 1, (n,1))]).reshape(-1,1)\n",
    "theta_0 = np.array([0.0])\n",
    "p = theta_0.shape[0]\n",
    "eps = 0.01\n",
    "eta = 0.001*np.eye(p)\n",
    "alpha = 0.01*np.eye(p)\n",
    "V = np.eye(p)\n",
    "batch_size = n\n",
    "niter = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$U(\\theta) = 2\\theta^2+\\theta^4$  \n",
    "$\\nabla U(\\theta) = -4\\theta + 4\\theta^3$  \n",
    "$\\nabla\\tilde{U}(\\theta) = \\nabla U(\\theta)+\\mathcal{N}(0,4) = -4\\theta + 4\\theta^3 + \\mathcal{N}(0,4)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U(theta):\n",
    "    return 2*theta**2+theta**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradU_noise(theta, x, n, batch_size):\n",
    "    '''noisy gradient from paper fig1'''\n",
    "    return -4*theta + 4*theta**3 + np.random.normal(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_batch(data, batch_size):\n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]\n",
    "    if n % batch_size !=0:\n",
    "        n = (n // batch_size)*batch_size\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    n_batch = n//batch_size\n",
    "    data = data[idx].reshape(batch_size, p, n_batch)\n",
    "    return(data, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pos_def(A):\n",
    "    '''function to check if matrix is positive definite'''\n",
    "    return np.all(np.linalg.eigvals(A) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sghmc(gradU, eps, C, Minv, theta_0, V_hat, niter, data, batch_size):\n",
    "    \n",
    "    '''Define SGHMC as dscribed in\n",
    "    Stochastic Gradient Hamilton Monte Carlo, ICML 2014\n",
    "    Tianqi Chen, Emily B. Fox, Carlos Guestrin.\n",
    "    \n",
    "    n: number of observations in data\n",
    "    p: dimension of parameters\n",
    "    \n",
    "    Inputs:\n",
    "        gradU: function with parameter(theta), gradient of U\n",
    "        \n",
    "        eps: learning rate\n",
    "        \n",
    "        C: friction matrix, with shape (p,p)\n",
    "        \n",
    "        Minv: Mass matrix, with shape (p,p)\n",
    "        \n",
    "        theta_0: initial value for sampling\n",
    "        \n",
    "        V_hat: estimated covariance matrix of stochastic gradient noise\n",
    "        \n",
    "        niter: number of samples to generate\n",
    "        \n",
    "        batch_size: size of a minibatch in an iteration\n",
    "        \n",
    "    \n",
    "    Output:\n",
    "        theta_samp: np.array sampled thetas\n",
    "    '''\n",
    "    \n",
    "    ###Initialization and condition check###\n",
    "    \n",
    "    p = len(theta_0)\n",
    "    n = data.shape[0]\n",
    "    \n",
    "    theta_samp = np.zeros((p, niter*(n//batch_size)))\n",
    "    \n",
    "    B_hat = 0.5*eps*V_hat\n",
    "    sqrt_noise = la.sqrtm(2*(C-B_hat)*eps)\n",
    "    \n",
    "    theta = theta_0\n",
    "    sqrtM = la.sqrtm(la.inv(Minv))\n",
    "    r = np.random.multivariate_normal(np.zeros(p), sqrtM).reshape(p, -1)\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(niter):\n",
    "        dat_batch, nbatches = data_batch(data, batch_size)\n",
    "        \n",
    "        r = np.random.multivariate_normala(np.zeros(p), sqrtM).reshape(p, -1)\n",
    "        \n",
    "        for batch in range(nbatches):\n",
    "            theta = theta + (eps*Minv@r).ravel()\n",
    "            gradU_batch = gradU(theta, dat_batch[:,:, batch], n, batch_size).reshape(p, -1)\n",
    "            r = r-eps@gradU_batch - eps*C@Minv@r \\\n",
    "                + np.random.multivariate_normal(np.zeros(p), sqrt_noise).reshape(p, -1)\n",
    "            \n",
    "            theta_samp[:,j] = theta\n",
    "            j = j+1\n",
    "            \n",
    "    return theta_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sghmc_momentum(gradU, eta, niter, alpha, theta_0, V_hat, data, batch_size):\n",
    "    '''Define SGHMC as described in \n",
    "    Stochastic Gradient Hamilton Monte Carlo, ICML 2014\n",
    "    Tianqi Chen, Emily B. Fox, Carlos Guestrin.\n",
    "    \n",
    "    n: number of observations in data\n",
    "    p: dimension of parameters \n",
    "    \n",
    "    Inputs:\n",
    "        gradU: function with parameter(theta), gradient of U\n",
    "        \n",
    "        eta: eps^2 M^(-1) where eps is the learning rate (detail in paper)\n",
    "        \n",
    "        niter: number of samples to generate\n",
    "        \n",
    "        alpha: eps M^(-1) C where C is a friction term (detail in paper)\n",
    "        \n",
    "        V_hat: estimated covariance matrix of stochastic gradient noise\n",
    "        \n",
    "        theta_0: initial value for sampling\n",
    "        \n",
    "        batch_size: size of a minibatch in an iteration\n",
    "    \n",
    "    Out:\n",
    "        np.array sampled thetas\n",
    "    '''\n",
    "    \n",
    "    ### Initialization and condition check ###\n",
    "    p = len(theta_0)\n",
    "    n = data.shape[0]\n",
    "    \n",
    "    #set up matrix to store samples\n",
    "    theta_samp = np.zeros((p, niter*(n//batch_size)))\n",
    "    \n",
    "    #beta_hat as p6 mentions\n",
    "    beta_hat = 0.5*V_hat @ eta\n",
    "    \n",
    "    #since we sample from N(0, 2(alpha - beta_hat)eta)\n",
    "    #the variance matrix must be positive definite\n",
    "    Sigma = 2*(alpha - beta_hat) @ eta\n",
    "    \n",
    "    if not is_pos_def(Sigma):\n",
    "        print(\"Error: (alpha - beta_hat) eta is not positive definite\")\n",
    "        return\n",
    "    \n",
    "    #batch size <= number of observations\n",
    "    if batch_size > n:\n",
    "        print(\"Error: batch_size must not be larger than number of observations\")\n",
    "        return\n",
    "    \n",
    "    #initialize\n",
    "    theta = theta_0\n",
    "    nu = np.random.multivariate_normal(np.zeros(p), eta).reshape(p, -1)\n",
    "    \n",
    "    #sampling\n",
    "    j = 0\n",
    "    for i in range(niter):\n",
    "        \n",
    "        dat_batch, nbatches = data_batch(data, batch_size)\n",
    "        \n",
    "        #resample nu every time\n",
    "        nu = np.random.multivariate_normal(np.zeros(p), eta).reshape(p, -1)\n",
    "        \n",
    "        for batch in range(nbatches):\n",
    "            gradU_batch = gradU(theta, dat_batch[:,:, batch], n, batch_size).reshape(p, -1)\n",
    "            nu = nu-eta@gradU_batch - alpha@nu + np.random.multivariate_normal(np.zeros(p), Sigma).reshape(p, -1)\n",
    "            theta = theta + nu\n",
    "            theta_samp[:,j] = theta.T\n",
    "            j = j+1\n",
    "            \n",
    "    return theta_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06417087, -0.06319911, -0.10133339, ...,  1.09411835,\n",
       "         1.05997912,  1.05961883]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sghmc_momentum(gradU_noise, eta, niter, alpha, theta_0, V, x, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
